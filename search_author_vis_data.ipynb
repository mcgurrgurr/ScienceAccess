{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown Cell Example \n",
    "markdown can be readibly interleaved and dispersed between code in notebooks \n",
    "## Explanation of code below\n",
    "The histogram (x-axis) binned readability score, (y-axis) counts of papers that occupy that readability score. \n",
    "\n",
    "The histogram is initially populated exclusively by the ART corpus, but the idea was every time a new author got scraped from scholar, it would be added in, such that with each persons new search our big picture of science readability would be better informed.\n",
    "\n",
    "So the histogram changes a little modestly perceptible amount with the author scrape, but three dots pertaining to the authors easiest read, hardest read, and mean read where added.\n",
    "\n",
    "These used to be ```[mean-standard dev, mean, mean+standard dev]``` but there was a flaw implementing that. It could just be that the plot looked way too busy around the mean, and it was harder to look at.\n",
    "\n",
    "There is an issue with getting the dots to appear in the centre of histogram bins. I was working under the assumption, that if I knew the ```[min,mean,max]```, readability scores for Rick Gerkin, I could add to them half the bin width, and dot's would be centred. That is almost correct. I forgot that these calculations are not performed on pre binned data, so the x-coordinates of ```[min,mean,max]``` need to be slightly shifted to the nearest histogram bin start first.\n",
    "\n",
    "Think of it as a bit like snapping something to a grid in photoshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/rjjarvis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rjjarvis/git/wcomplexity_dash/t_analysis.py:21: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/anaconda3/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/anaconda3/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n",
      "    handle._run()\n",
      "  File \"/anaconda3/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-dca84f91f6eb>\", line 4, in <module>\n",
      "    from online_app_backend import call_from_front_end\n",
      "  File \"/Users/rjjarvis/git/wcomplexity_dash/online_app_backend.py\", line 2, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n",
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scholar.google.com/scholar?hl=en&as_sdt=0%2C3&q=R Gerkin\n",
      "> /Users/rjjarvis/git/wcomplexity_dash/online_app_backend.py(60)take_url_from_gui()\n",
      "-> follow_links = collect_pubs(author_link_scholar_link_list)[0:25]\n",
      "(Pdb) c\n",
      "['https://accounts.google.com/Login?hl=en&continue=https://scholar.google.com/scholar%3Fhl%3Den%26as_sdt%3D0%252C3%26q%3DR%2520Gerkin', 'https://accounts.google.com/Login?hl=en&continue=https://scholar.google.com/scholar%3Fhl%3Den%26as_sdt%3D0%252C3%26q%3DR%2520Gerkin', 'https://www.nature.com/articles/nn1387', 'https://www.sciencedirect.com/science/article/pii/S0196064405810212', 'https://www.jneurosci.org/content/jneuro/24/29/6466.full.pdf', 'https://www.jneurosci.org/content/24/29/6466.short', 'https://pubs.acs.org/doi/pdf/10.1021/ja00736a021', 'https://www.tandfonline.com/doi/abs/10.1080/15298660008984572', 'https://www.physiology.org/doi/full/10.1152/jn.00803.2004', 'https://www.physiology.org/doi/abs/10.1152/jn.00803.2004', 'https://www.sciencedirect.com/science/article/pii/S1047847700942928', 'https://journals.lww.com/thehearingjournal/00043764-200105000-00007.fulltext', 'https://ajp.psychiatryonline.org/doi/pdfplus/10.1176/ajp.2007.164.6.916', 'https://ajp.psychiatryonline.org/doi/abs/10.1176/ajp.2007.164.6.916', 'https://onlinelibrary.wiley.com/doi/abs/10.1002/app.1979.070240912', 'http://www.paper.edu.cn/scholar/showpdf/MUz2AN2INTA0eQxeQh', 'http://clinicalmonster.com/blog/wp-content/uploads/2013/10/black-widow.pdf', 'http://brandfacket.se/download/cancerstudier/characterization_of_firefighter_exposures_during_fire_overhaul.pdf', 'http://www.academia.edu/download/38134524/cowley-janney-gerkin-buseck.pdf']\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: Browsing context has been discarded\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/Users/rjjarvis/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/git/wcomplexity_dash/online_app_backend.py\u001b[0m in \u001b[0;36mtake_url_from_gui\u001b[0;34m(author_link_scholar_link_list)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mfollow_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_pubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_link_scholar_link_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/wcomplexity_dash/get_bmark_corpus.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(link)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0murlDat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufferd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0murlDat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m#content = C.open(link).content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/wcomplexity_dash/t_analysis.py\u001b[0m in \u001b[0;36mtext_proc\u001b[0;34m(corpus, urlDat, WORD_LIM)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;31m#We create a list comprehension which only returns a list of words #that are NOT IN stop_words and NOT IN punctuations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/Users/rjjarvis/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/anaconda3/nltk_data'\n    - '/anaconda3/share/nltk_data'\n    - '/anaconda3/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dca84f91f6eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monline_app_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall_from_front_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcall_from_front_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R Gerkin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/wcomplexity_dash/online_app_backend.py\u001b[0m in \u001b[0;36mcall_from_front_end\u001b[0;34m(NAME, tour, NAME1, verbose)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtour\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mscholar_link\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://scholar.google.com/scholar?hl=en&as_sdt=0%2C3&q='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0menter_name_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscholar_link\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_author_specific'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscholar_link\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/wcomplexity_dash/online_app_backend.py\u001b[0m in \u001b[0;36menter_name_here\u001b[0;34m(scholar_page, name)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0menter_name_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscholar_page\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_web_form\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscholar_page\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;31m#author_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     '''\n",
      "\u001b[0;32m~/git/wcomplexity_dash/online_app_backend.py\u001b[0m in \u001b[0;36mupdate_web_form\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m#data = author_results = {}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mauthor_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_url_from_gui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;31m#data[name] = author_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/wcomplexity_dash/online_app_backend.py\u001b[0m in \u001b[0;36mtake_url_from_gui\u001b[0;34m(author_link_scholar_link_list)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mfollow_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollect_pubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_link_scholar_link_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfollow_links\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/wcomplexity_dash/crawl.py\u001b[0m in \u001b[0;36mcollect_pubs\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFirefox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mcrude_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \"\"\"\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m#print(url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mpage_source\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \"\"\"\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_PAGE_SOURCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: Browsing context has been discarded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from online_app_backend import call_from_front_end\n",
    "\n",
    "call_from_front_end(\"R Gerkin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.html import widgets # Widget definitions\n",
    "\n",
    "\n",
    "#from __future__ import print_function\n",
    "from IPython.html import widgets # Widget definitions\n",
    "#import ipywidgets #as widgetsss\n",
    "# Create text widget for output\n",
    "year_output = widgets.Text()\n",
    "\n",
    "# Create text widget for input\n",
    "year_input = widgets.Text(\n",
    "    placeholder=\"Enter scholar Author\",\n",
    "    description='Query:',\n",
    "    disabled=False\n",
    "    )\n",
    "\n",
    "# Define function to bind value of the input to the output variable\n",
    "def bind_input_to_output(sender):\n",
    "    year_output.value = year_input.value\n",
    "    print(year_output.value)\n",
    "\n",
    "# Tell the text input widget to call bind_input_to_output() on submit\n",
    "year_input.on_submit(bind_input_to_output)\n",
    "\n",
    "# Display input text box widget for input\n",
    "display(year_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be easy to hack this code to run off a local machine, using sudo.\n",
    "Set up the Environment. This is now done in requirements, and the postBuild script.\n",
    "```python\n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "\n",
    "if os.path.exists('traingDats.p?dl=0'):\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    !wget https://www.dropbox.com/s/3h12l5y2pn49c80/traingDats.p?dl=0\n",
    "    !wget https://www.dropbox.com/s/crarli3772rf3lj/more_authors_results.p?dl=0\n",
    "    !wget https://www.dropbox.com/s/x66zf52himmp5ox/benchmarks.p?dl=0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import copy\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import glob\n",
    "files = glob.glob(\"*.p\")\n",
    "discontents = pickle.load(open(\"_author_specificS S Phatak.p\",\"rb\"))\n",
    "type(discontents[0])\n",
    "df = discontents[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('scraped_new.p?dl=0','rb') as f:\n",
    "        texts = pickle.load(f) \n",
    "except:\n",
    "    !wget https://www.dropbox.com/s/1kc7alp79h701hx/scraped_new.p?dl=0\n",
    "    with open('scraped_new.p?dl=0','rb') as f:\n",
    "        texts = pickle.load(f) \n",
    "\n",
    "queries = set([t['query'] for t in texts ])\n",
    "temp = [t for t in texts if 'standard' in t.keys() and 'wikipedia' in t['link']]\n",
    "science = ['cancer','Vaccines','evolution','climate change','Transgenic','photosysnthesis','evolution','GMO']\n",
    "res = [t['standard'] for t in temp if t['query'] in science]\n",
    "mwp = np.mean(res)  \n",
    "abstract_wiki = {'standard':mwp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if os.path.exists('traingDats.p?dl=0'):\n",
    "    pass\n",
    "\n",
    "else:\n",
    "    !wget https://www.dropbox.com/s/3h12l5y2pn49c80/traingDats.p?dl=0\n",
    "    !wget https://www.dropbox.com/s/crarli3772rf3lj/more_authors_results.p?dl=0\n",
    "    !wget https://www.dropbox.com/s/x66zf52himmp5ox/benchmarks.p?dl=0\n",
    "with open('traingDats.p?dl=0','rb') as f:\n",
    "        trainingDats = pickle.load(f) \n",
    "\n",
    "bmark = pickle.load(open('benchmarks.p?dl=0','rb'))\n",
    "\n",
    "ar = discontents[2]\n",
    "np.mean(df['standard'])\n",
    "NAME = \"Sayali S. Phatak\"\n",
    "trainingDats.extend(bmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([b['standard'] for b in bmark])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_heights(stats_items,histogram_content,x_sub_set):\n",
    "    vertical_postions_indexs = []\n",
    "    for i in stats_items:\n",
    "        vertical_postions_indexs.append(find_nearest(histogram_content, i))\n",
    "    bin_width_offset = (xys[1][0] - xys[0][0])/2.0\n",
    "    x_sub_set = [ i+bin_width_offset for i in x_sub_set ]\n",
    "\n",
    "\n",
    "    heights = []\n",
    "    for i in vertical_postions_indexs:\n",
    "        heights.append(xys[i][1])\n",
    "    return heights, bin_width_offset\n",
    "\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def snap_to_grid(author_stats,bin_centers):\n",
    "    author_stats_grid = []\n",
    "    for as_ in author_stats:\n",
    "        as_ = find_nearest(bin_centers,as_)\n",
    "        author_stats_grid.append(bin_centers[as_])\n",
    "    return author_stats_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ART = np.max([ t['standard'] for t in trainingDats ])\n",
    "publication = [ t['publication'] for t in trainingDats if t['standard'] == max_ART ]\n",
    "keys = [ t.keys() for t in trainingDats if t['standard'] == max_ART ]\n",
    "\n",
    "fname = [ t['file_name'] for t in trainingDats if t['standard'] == max_ART ]\n",
    "bmark_max_art = {'standard':max_ART}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "\n",
    "standard_sci = [ t['standard'] for t in trainingDats ]\n",
    "ar = [ t for t in ar if type(t) is type({})]\n",
    "ar = [ t for t in ar if 'standard' in t.keys()]\n",
    "xys = [ (h.get_x(),h.get_height()) for h in sns.distplot(standard_sci).patches ]\n",
    "\n",
    "x_grid = [ h.get_x() for h in sns.distplot(standard_sci).patches ]\n",
    "offset = float((x_grid[1] - x_grid[0])/2.0)\n",
    "bin_centers = [gr+offset for gr in x_grid]\n",
    "# this plot not used yet.\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8), dpi=80)\n",
    "ax1 = fig.add_subplot(111)#)\n",
    "mean_ = np.mean([a['standard'] for a in ar])\n",
    "min_ = np.min([a['standard'] for a in ar])\n",
    "max_ = np.max([a['standard'] for a in ar])\n",
    "std_ = np.std([a['standard'] for a in ar])\n",
    "stats_items = [mean_,min_,max_]\n",
    "\n",
    "g = sns.distplot(standard_sci, label=\"Readability Index\")\n",
    "\n",
    "\n",
    "histogram_content = [x[0] for x in xys]\n",
    "height_content = np.array([x[1] for x in xys])\n",
    "\n",
    "hc = np.array(histogram_content)\n",
    "\n",
    "x_sub_set=histogram_content\n",
    "\n",
    "\n",
    "other_name=str('Phytochromobilin C15-Z,syn - C15-E,anti isomerization: concerted or stepwise?')\n",
    "worst_height,_ = get_heights([max_ART],hc,x_sub_set)\n",
    "mwp_height,_ = get_heights([mwp],hc,x_sub_set)\n",
    "\n",
    "#bmark_max_art\n",
    "worst_height = worst_height[0]\n",
    "#bmark_stats_items_grid = snap_to_grid(bmark_stats_items,bin_centers)\n",
    "\n",
    "#worst_distamnce = snap_to_grid(max_ART,bin_centers)\n",
    "worst_distance = snap_to_grid([max_ART],bin_centers)\n",
    "mwp_distance = snap_to_grid([mwp],bin_centers)\n",
    "x,y,z = (mwp_distance[0],mwp_height[0],str('mean wikipedia'))\n",
    "\n",
    "#print(bmark)\n",
    "bmark_stats_items = list(set([ b['standard'] for b in bmark ]))\n",
    "bmark_stats_items.append(x)\n",
    "#bmark_stats_items.append(max_ART)\n",
    "bmark_heights, _ = get_heights(bmark_stats_items,histogram_content,x_sub_set)\n",
    "heights, bwo = get_heights(stats_items,histogram_content,x_sub_set)\n",
    "#bmark_heights.append(worst_height)\n",
    "bmark_stats_items = [i+bwo for i in bmark_stats_items]\n",
    "mean_a = mean_\n",
    "min_a = min_ \n",
    "max_a = max_ \n",
    "xticks = list(range(0,45,5))\n",
    "\n",
    "#print(xticks)\n",
    "bmark_stats_items\n",
    "box_content = [a['standard'] for a in ar]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bmark_stats_items_grid = snap_to_grid(bmark_stats_items,bin_centers)\n",
    "author_stats =[i for i in [mean_,min_,max_]]\n",
    "author_stats_grid = snap_to_grid(author_stats,bin_centers)\n",
    "mean_a_grid = snap_to_grid([mean_a],bin_centers)\n",
    "x_sub_set_grid = snap_to_grid(x_sub_set,bin_centers)\n",
    "\n",
    "print(bmark_stats_items_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [ \"Readibility of Science Declining Over Time\", \"Post Modern Essay Generator\",\"upgoer 5\",\"Science of Writing\",\"Mean Wikipedia\"]#\"Mean Wikipedia\"]#,other_name]# \"wikipedia science\"]\n",
    "bmark_stats_items_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalibrate_heights,b = get_heights(author_stats_grid,hc,x_sub_set)\n",
    "\n",
    "heights[0] = np.max(recalibrate_heights)\n",
    "heights[2] = recalibrate_heights[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(height_content)\n",
    "heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmark_heights\n",
    "print(len(bmark_heights))\n",
    "print(len(bin_centers))\n",
    "print(len(bmark_stats_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bmark_stats_items_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.array(ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmark_stats_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categories\n",
    "#categories.insert(3,'Mean Wikipedia Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xinterval\n",
    "x1,y1,z1 = (mwp_distance[0],mwp_height[0],str('mean wikipedia'))\n",
    "x1\n",
    "#bmark_heights[3]=y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(bmark_stats_items_grid)\n",
    "import copy\n",
    "#del bmark_stats_items_grid[-2]\n",
    "#del bmark_stats_items_grid[-1]\n",
    "xinterval1 = copy.copy(bmark_stats_items_grid)\n",
    "#xinterval1.insert(3,x1)\n",
    "#xinterval1\n",
    "#del bmark_heights[-1]\n",
    "bmark_heights\n",
    "print(len(bmark_heights))\n",
    "print(len(bmark_stats_items_grid))\n",
    "\n",
    "benchmarks = pd.DataFrame({\n",
    "'benchmarks': bmark_stats_items_grid,\n",
    "    'CDF': bmark_heights\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10, 10),nrows=2, ncols=1, sharex=True, dpi=100)\n",
    "\n",
    "\n",
    "g = sns.distplot(standard_sci, label=\"Readability Index\")\n",
    "\n",
    "\n",
    "if str('data0') not in locals():\n",
    "    data0 = pd.DataFrame({\n",
    "    'mean, min, maximum': author_stats_grid,\n",
    "        'CDF': heights\n",
    "        })\n",
    "\n",
    "\n",
    "    data2 = pd.DataFrame({\n",
    "    'Standard Reading Level': mean_a_grid,\n",
    "        'CDF': np.max(height_content)\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "legend_properties = {'weight':'bold','size':8}\n",
    "ax = sns.regplot(data=benchmarks, x=\"benchmarks\", y=\"CDF\", fit_reg=False, marker=\"o\", color=\"green\")\n",
    "ax = sns.regplot(data=data2, x=\"Standard Reading Level\", y=\"CDF\", fit_reg=False, marker=\"o\", color=\"red\")\n",
    "legendMain=ax.legend(labels=[str(\"std deviation\")], prop=legend_properties,loc='upper right')\n",
    "legendSide0=ax.legend(labels=[NAME],prop=legend_properties,loc='center right')\n",
    "legendSide1=ax.legend(labels=[str('Number of Documents: '+str(len(ar)))],prop=legend_properties,loc='upper left')\n",
    "legendMain=ax.legend(labels=[str(\"Google scholar author relative to ART Corpus distribution. Total docs: \")+str(len(trainingDats))], prop=legend_properties,loc='upper left')\n",
    "#\n",
    "print(categories)\n",
    "x,y,z = (worst_distance[0],worst_height,other_name)\n",
    "data3 = pd.DataFrame({\n",
    "'Standard Reading Level': [x1],\n",
    "    'CDF': [y1]\n",
    "    })\n",
    "ax = sns.regplot(data=data3, x='Standard Reading Level', y=\"CDF\", fit_reg=False, marker=\"o\", color=\"green\")\n",
    "\n",
    "\n",
    "axes[1] = ax = sns.regplot(data=benchmarks, x=\"benchmarks\", y=\"CDF\", fit_reg=False, marker=\"o\", color=\"green\")\n",
    "\n",
    "ax2 = plt.twiny()\n",
    "xticks = list(range(0,45,5))\n",
    "ax2.set_xticks(xticks)\n",
    "\n",
    "axes[1].set_xticks(xinterval1)\n",
    "axes[1].set_xticklabels(categories, minor=False, rotation=90)\n",
    "\n",
    "axes[1].axvline(np.mean(standard_sci), color='red', alpha=.7, linewidth=1.5)\n",
    "axes[1].set_ylabel('Probability of Document Reading Level')\n",
    "axes[1].set_xlabel('Reading Grade Level')\n",
    "bp_dict = axes[0].boxplot(box_content, 0, 'gD', vert=False)\n",
    "\n",
    "\n",
    "for line in bp_dict['medians']:\n",
    "    x, y = line.get_xydata()[1] # top of median line\n",
    "\n",
    "for line in bp_dict['boxes']:\n",
    "    x0, y = line.get_xydata()[0] # bottom of left line\n",
    "    axes[0].text(x0,y, str(NAME)+' Q1 ',horizontalalignment='center',verticalalignment='top',rotation=90)\n",
    "\n",
    "    x1, y = line.get_xydata()[3] # bottom of right line\n",
    "    axes[0]. text(x1,y, str(NAME)+' Q3 ',horizontalalignment='center',verticalalignment='top',rotation=90)\n",
    "\n",
    "    axes[0]. text(np.abs(x1+x0)/2,y, str(NAME)+' $\\mu$ ',horizontalalignment='center',verticalalignment='top',rotation=90)\n",
    "    x2, y = line.get_xydata()[1] # bottom of right line\n",
    "axes[0].axvline(np.mean(standard_sci), color='red', alpha=.7, linewidth=1.5)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmark_stats_items_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
